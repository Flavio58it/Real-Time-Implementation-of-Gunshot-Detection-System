{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fawad\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import load_model\n",
    "from sklearn.svm import SVC\n",
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import requests\n",
    "from time import sleep\n",
    "from tqdm import tqdm_notebook\n",
    "from warnings import catch_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fawad\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator PCA from version 0.19.1 when using version 0.18.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pca=joblib.load('PCAOBJECTNEW.pkl')\n",
    "autoencoder1=load_model('autoencoderFirst.h5')\n",
    "autoencoder2=load_model('autoencodersecond.h5')\n",
    "autoencoder3=load_model('autoencoderthird.h5')\n",
    "IF=joblib.load('IF.pkl')\n",
    "SLF=joblib.load('SVMlinearFirst.pkl')\n",
    "SLS=joblib.load('SVMlinearsecond.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autoencoder setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "PLEASE WAIT, WHILE THE AUTOENCODER SETUP IS DONE:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832d2302445541849fe95092fa3caddd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup is done:  3872.0 2930.0 4340.0\n",
      "******************************************\n"
     ]
    }
   ],
   "source": [
    "path='./realtimefolder/'\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 22050\n",
    "RECORD_SECONDS =1\n",
    "losses1=np.zeros(10,dtype=np.float16)\n",
    "losses2=np.zeros(10,dtype=np.float16)\n",
    "losses3=np.zeros(10,dtype=np.float16)\n",
    "print('******************************************')\n",
    "print('PLEASE WAIT, WHILE THE AUTOENCODER SETUP IS DONE:')\n",
    "for ii in tqdm_notebook(range(10)):\n",
    "    WAVE_OUTPUT_FILENAME = \"background\"+\".wav\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    output=True,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(path+\"\\\\\"+WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(np.array(frames).ravel())\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "    timeseries=librosa.load('./realtimefolder/background.wav')[0]\n",
    "    if len(timeseries)==3*22050:\n",
    "        pass\n",
    "    else:\n",
    "        timeseries=np.concatenate((timeseries,np.zeros(3*22050 - len(timeseries))))\n",
    "\n",
    "    a= librosa.feature.chroma_cens(timeseries).ravel()\n",
    "    b= librosa.feature.chroma_cqt(timeseries).ravel()\n",
    "    c= librosa.feature.chroma_stft(timeseries,S=np.abs(librosa.stft(timeseries))).ravel()\n",
    "    d= librosa.feature.delta(librosa.feature.melspectrogram(timeseries,n_mels=20)).ravel()\n",
    "    e= librosa.feature.melspectrogram(timeseries,n_mels=20).ravel()\n",
    "    f= librosa.feature.mfcc(timeseries,n_mfcc=40).ravel()\n",
    "    g= librosa.feature.poly_features(timeseries).ravel()\n",
    "    h= librosa.feature.rmse(timeseries).ravel()\n",
    "    i= librosa.feature.spectral_bandwidth(timeseries).ravel() \n",
    "    j= librosa.feature.spectral_centroid(timeseries).ravel()\n",
    "    k= librosa.feature.spectral_contrast(timeseries).ravel()\n",
    "    l= librosa.feature.spectral_flatness(timeseries).ravel()\n",
    "    m= librosa.feature.spectral_rolloff(timeseries).ravel()\n",
    "    n= librosa.feature.tempogram(timeseries,win_length=10).ravel() \n",
    "    o= librosa.feature.tonnetz(timeseries).ravel()\n",
    "    p= librosa.feature.zero_crossing_rate(timeseries).ravel() \n",
    "    features=np.concatenate((a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p))\n",
    "\n",
    "    \n",
    "    pca_audio=pca.transform(features.reshape(1,-1))\n",
    "    prediction=autoencoder1.predict(pca_audio)\n",
    "    losses1[ii]=np.linalg.norm(pca_audio - prediction)\n",
    "    prediction=autoencoder2.predict(pca_audio)\n",
    "    losses2[ii]=np.linalg.norm(pca_audio - prediction)\n",
    "    prediction=autoencoder3.predict(pca_audio)\n",
    "    losses3[ii]=np.linalg.norm(pca_audio - prediction)\n",
    "threshold1=losses1.min()\n",
    "threshold2=losses2.min()\n",
    "threshold3=losses3.min()\n",
    "print('Setup is done: ',threshold1,threshold2,threshold3)\n",
    "print('******************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zeeshan wala code edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "Gunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "Gunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "Gunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "Gunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "Gunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n",
      "NotGunshot\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-996e7b2f67f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRATE\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mCHUNK\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mRECORD_SECONDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\fawad\\Anaconda3\\lib\\site-packages\\pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[0;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path='./realtimefolder/'\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 22050\n",
    "RECORD_SECONDS =1\n",
    "for i in range(100):\n",
    "    Gunshot=0\n",
    "    NotGunshot=0\n",
    "    WAVE_OUTPUT_FILENAME = \"background\"+\".wav\"\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    output=True,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(path+\"\\\\\"+WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(np.array(frames).ravel())\n",
    "    wf.close()\n",
    "    \n",
    "\n",
    "    timeseries=librosa.load('./realtimefolder/background.wav')[0]\n",
    "    if len(timeseries)==3*22050:\n",
    "        pass\n",
    "    else:\n",
    "        timeseries=np.concatenate((timeseries,np.zeros(3*22050 - len(timeseries))))\n",
    "\n",
    "    a= librosa.feature.chroma_cens(timeseries).ravel()\n",
    "    b= librosa.feature.chroma_cqt(timeseries).ravel()\n",
    "    c= librosa.feature.chroma_stft(timeseries,S=np.abs(librosa.stft(timeseries))).ravel()\n",
    "    d= librosa.feature.delta(librosa.feature.melspectrogram(timeseries,n_mels=20)).ravel()\n",
    "    e= librosa.feature.melspectrogram(timeseries,n_mels=20).ravel()\n",
    "    f= librosa.feature.mfcc(timeseries,n_mfcc=40).ravel()\n",
    "    g= librosa.feature.poly_features(timeseries).ravel()\n",
    "    h= librosa.feature.rmse(timeseries).ravel()\n",
    "    i= librosa.feature.spectral_bandwidth(timeseries).ravel() \n",
    "    j= librosa.feature.spectral_centroid(timeseries).ravel()\n",
    "    k= librosa.feature.spectral_contrast(timeseries).ravel()\n",
    "    l= librosa.feature.spectral_flatness(timeseries).ravel()\n",
    "    m= librosa.feature.spectral_rolloff(timeseries).ravel()\n",
    "    n= librosa.feature.tempogram(timeseries,win_length=10).ravel() \n",
    "    o= librosa.feature.tonnetz(timeseries).ravel()\n",
    "    p= librosa.feature.zero_crossing_rate(timeseries).ravel() \n",
    "    features=np.concatenate((a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p))\n",
    "\n",
    "    \n",
    "    pca_audio=pca.transform(features.reshape(1,-1))\n",
    "    \n",
    "    prediction=autoencoder1.predict(pca_audio)\n",
    "    loss=np.linalg.norm(pca_audio - prediction)\n",
    "    if loss>threshold1:\n",
    "        NotGunshot+=1\n",
    "    else:\n",
    "        Gunshot+=1\n",
    "    prediction=autoencoder2.predict(pca_audio)\n",
    "    loss=np.linalg.norm(pca_audio - prediction)\n",
    "    if loss>threshold2:\n",
    "        NotGunshot+=1\n",
    "    else:\n",
    "        Gunshot+=1\n",
    "#    prediction=autoencoder3.predict(pca_audio)\n",
    "#    loss=np.linalg.norm(pca_audio - prediction)\n",
    "#    if loss>threshold3:\n",
    "#        NotGunshot+=1\n",
    "#    else:\n",
    "#        Gunshot+=1\n",
    "        \n",
    "    if IF.predict(pca_audio)[0]<0:\n",
    "        NotGunshot+=1\n",
    "    else:\n",
    "        Gunshot+=1   \n",
    "    if SLF.predict(pca_audio)[0]<0:\n",
    "        NotGunshot+=1\n",
    "    else:\n",
    "        Gunshot+=1    \n",
    "        \n",
    "    if SLS.predict(pca_audio)[0]<0:\n",
    "        NotGunshot+=1\n",
    "    else:\n",
    "        Gunshot+=1    \n",
    "        \n",
    "        \n",
    "    if Gunshot>=2:\n",
    "        print('Gunshot')\n",
    "    else:\n",
    "        print('NotGunshot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
